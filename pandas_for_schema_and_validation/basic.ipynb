{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  example\n",
    "#  wrong letting pandas guess\n",
    "from numpy import dtype\n",
    "from pandas._typing import DtypeArg\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"dates_test.csv\")\n",
    "\n",
    "# you provide explicit dtypes\n",
    "dtype_spec:DtypeArg = {\n",
    "    'user_id': 'Int64',\n",
    "    'user_name': 'string',\n",
    "    'age': 'Int64',\n",
    "    'salary': 'Float64',\n",
    "    'is_active': 'boolean'\n",
    "}\n",
    "\n",
    "df = pd.read_csv('dates_test.csv',dtype=dtype_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Without dtype specification\n",
    "# CSV contains: user_id,score\n",
    "#               001,95\n",
    "#               002,88\n",
    "\n",
    "df_inferred = pd.read_csv('scores.csv')\n",
    "print(df_inferred.dtypes)\n",
    "# user_id: int64  (leading zeros lost!)\n",
    "# score: int64\n",
    "# # With explicit dtypes\n",
    "df_explicit = pd.read_csv('scores.csv', dtype={'user_id': 'string', 'score': 'int64'})\n",
    "print(df_explicit['user_id'])\n",
    "df_explicit\n",
    "# # 0    001\n",
    "# # 1    002\n",
    "# # Preserves leading zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  this is massive issue\n",
    "# object = “I cannot represent this data efficiently, so I’ll store generic Python objects.”\n",
    "pd.Series([True, False, None])\n",
    "\n",
    "# use this\n",
    "# pd.Series([True, False, None], dtype=\"boolean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  well. this None is not numpy thing as there not thing ie to store a missing value so even if you use numpy.nan the issue will be the same\n",
    "# from numpy import int64\n",
    "\n",
    "\n",
    "pd.Series([True, False, np.nan])\n",
    "#  this will still fall back to object bcz\n",
    "# It still falls back to object because NumPy’s boolean dtype (np.bool_) cannot represent NaN, even though np.nan itself comes from NumPy.\n",
    "#  distinction is Only floating-point NumPy dtypes can represent NaN.\n",
    "# pd.Series([1.0,2.0,0.3,None])\n",
    "\n",
    "#  checking for int array\n",
    "pd.Series([1,2,3,None]) # pandas will upgrade this so it could fit in None so it will become float array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <!--  working with datetime  -->\n",
    "\n",
    "# The actual NumPy-backed dtype pandas uses to store timestamps -> dtype=\"datetime64[ns]\"\n",
    "pd.Series(\n",
    "    [\"2024-01-01\", \"2024-01-02\", None],\n",
    "    dtype=\"datetime64[ns]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  if you donot provide dtype this time column whould be assumed to be a object\n",
    "print(pd.Series([\"a\", \"b\", None], dtype=\"string\"))\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#  without string this is object\n",
    "print(pd.Series([\"a\", \"b\", None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(x):\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(x, fmt)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def parse_date(x):\n",
    "    try:\n",
    "        return parser.parse(str(x), dayfirst=True)\n",
    "    except:\n",
    "        return pd.NaT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dates_test.csv\",parse_dates=['date'])\n",
    "# df['date_parsed'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df['date_parsed'] = df['date'].apply(parse_date) # type: ignore\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(\n",
    "    #  this is data ie the input\n",
    "    [\"train\", \"test\", \"dog\"],\n",
    "    #  these are the stored values which are checked for\n",
    "    categories=[\"train\", \"test\"]\n",
    ")\n",
    "# \"dog\" → NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(\n",
    "    [\"low\", \"medium\", \"high\"],\n",
    "    categories=[\"low\", \"medium\", \"high\"],\n",
    "    ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered vs unordered categories\n",
    "pd.Categorical(\n",
    "    [\"low\", \"medium\", \"high\"],\n",
    "    categories=[\"low\", \"medium\", \"high\"],\n",
    "    ordered=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    [\"low\", \"high\",'medium'],\n",
    "    dtype=pd.CategoricalDtype(\n",
    "        categories=[\"low\", \"medium\", \"high\"],\n",
    "        ordered=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Use this for:\n",
    "\n",
    "# filtering\n",
    "\n",
    "# conditions\n",
    "\n",
    "# business rules\n",
    "\n",
    "s[s < \"high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    [\"low\", \"high\"],\n",
    "    dtype=pd.CategoricalDtype(\n",
    "        categories=[\"low\", \"medium\", \"high\"],\n",
    "        ordered=False\n",
    "    )\n",
    ")\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using category type for quickl status check\n",
    "\n",
    "# Define allowed statuses\n",
    "status_dtype = pd.CategoricalDtype(\n",
    "    categories=[\"train\"],  # allowed values\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# Read CSV and enforce dtype\n",
    "df = pd.read_csv(\"./category_demodata_check.csv\", dtype={\"status\": status_dtype})\n",
    "df_filtered = df[df[\"status\"].notna()]\n",
    "df_filtered\n",
    "# This will raise an error if any value in 'status' is not in [\"train\", \"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define allowed categories\n",
    "status_dtype = pd.CategoricalDtype(\n",
    "    categories=['active', 'inactive', 'suspended'],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# This will raise an error if CSV contains invalid statuses\n",
    "try:\n",
    "    df = pd.read_csv('users.csv', dtype={'status': status_dtype})\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid category found: {e}\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical dtype\n",
    "status_dtype = pd.CategoricalDtype(\n",
    "    categories=['active', 'inactive', 'suspended'],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# Read as string first to check for invalid values\n",
    "df = pd.read_csv('users.csv', dtype={'status': str})\n",
    "\n",
    "# Validate before converting\n",
    "invalid_statuses = df[~df['status'].isin(status_dtype.categories)]\n",
    "\n",
    "if not invalid_statuses.empty:\n",
    "    print(\"Found invalid statuses:\")\n",
    "    print(invalid_statuses[['user_id', 'username', 'status']])\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Fix the CSV and reload\")\n",
    "    print(\"2. Replace invalid values with a default\")\n",
    "    print(\"3. Remove invalid rows\")\n",
    "else:\n",
    "    # Convert to categorical\n",
    "    df['status'] = df['status'].astype(status_dtype)\n",
    "    print(\"✓ All statuses valid and converted to categorical\")\n",
    "    print(f\"\\nMemory usage: {df['status'].memory_usage(deep=True)} bytes\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ordered categories\n",
    "\n",
    "# For rankings, ratings, etc.\n",
    "priority_dtype = pd.CategoricalDtype(\n",
    "    categories=['low', 'medium', 'high', 'critical'],\n",
    "    ordered=True\n",
    ")\n",
    "df = pd.read_csv(\"./task.csv\")\n",
    "df['priority'] = df['priority'].astype(priority_dtype)\n",
    "# # Now you can compare\n",
    "print(df[df['priority'] > 'medium'])  # Returns high and critical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_object = pd.DataFrame({'status': ['active'] * 1_000_000})\n",
    "df_category = pd.DataFrame({'status': pd.Categorical(['active'] * 1_000_000)})\n",
    "\n",
    "print(f\"Object dtype: {df_object.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Category dtype: {df_category.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Categorical(\n",
    "    [\"train\", \"test\", \"dog\"],\n",
    "    categories=[\"train\", \"test\"]\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "###  SCHEMA VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  USING ASTYPE\n",
    "#  example donot run\n",
    "df = df.astype({\n",
    "    \"id\": \"int64\",\n",
    "    \"price\": \"float64\",\n",
    "    \"created_at\": \"datetime64[ns]\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"age\": [25, None, 30],\n",
    "    \"active\": [True, False, None],\n",
    "    \"name\": [\"Alice\", None, \"Bob\"]\n",
    "})\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'age': [25, 30, 35],\n",
    "    'salary': [50000.50, 60000.00, 75000.75],\n",
    "    'is_manager': [True, False, True],\n",
    "    'hire_date': pd.to_datetime(['2023-01-15', '2022-06-01', '2024-03-10']),\n",
    "    'notes': ['Senior', 'Mid', np.nan]\n",
    "})\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import (\n",
    "    is_integer_dtype,\n",
    "    is_float_dtype,\n",
    "    is_numeric_dtype,\n",
    "    is_string_dtype,\n",
    "    is_object_dtype,\n",
    "    is_bool_dtype,\n",
    "    is_datetime64_any_dtype\n",
    ")\n",
    "\n",
    "# Check a single column\n",
    "print(is_numeric_dtype(df['age']))          # True\n",
    "print(is_string_dtype(df['name']))          # True (includes object with strings)\n",
    "print(is_datetime64_any_dtype(df['hire_date']))  # True\n",
    "\n",
    "# Find all numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Find all object/string columns\n",
    "string_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "print(\"String/object columns:\", string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
